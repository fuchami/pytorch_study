{"cells":[{"source":"# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\nimport os\ntry:\n\tos.chdir(os.path.join(os.getcwd(), '..'))\n\tprint(os.getcwd())\nexcept:\n\tpass\n","cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n",""]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(2.)\ntensor(1.)\ntensor(1.)\n"}],"source":["\"\"\"\n","requires_grad=Falseだと微分の対象にならず勾配はNoneが返る\n","Fie-tuningで層のパラメータを固定したいときに便利\n","計算グラフを構築してbackward()を実行するとグラフを構築する各変数のgradに勾配が入る\n","\"\"\"\n","x = torch.tensor(1.0, requires_grad=True)\n","w = torch.tensor(2.0, requires_grad=True)\n","b = torch.tensor(3.0, requires_grad=True)\n","\n","# 計算グラフを構築\n","y = w * x + b\n","# 勾配を計算\n","y.backward()\n","\n","# 勾配の表示\n","print(x.grad)\n","print(w.grad)\n","print(b.grad)\n",""]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(4.)\n"}],"source":["x = torch.tensor(2.0, requires_grad=True)\n","y = x ** 2\n","y.backward()\n","print(x.grad)\n",""]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(7.3891)\n"}],"source":["x = torch.tensor(2.0, requires_grad=True)\n","y = torch.exp(x)\n","y.backward()\n","print(x.grad)\n",""]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(-1.)\n"}],"source":["x = torch.tensor(np.pi, requires_grad=True)\n","y = torch.sin(x)\n","y.backward()\n","print(x.grad)\n",""]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(6.)\n"}],"source":["x = torch.tensor(0.0, requires_grad=True)\n","y = (x - 4) * ( x ** 2 + 6)\n","y.backward()\n","print(x.grad)\n",""]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(6.1820)\n"}],"source":["x = torch.tensor(2.0, requires_grad=True)\n","y = (torch.sqrt(x) + 1) ** 3\n","y.backward()\n","print(x.grad)\n",""]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(10.)\ntensor(20.)\nw: Parameter containing:\ntensor([[-0.2650, -0.4728,  0.4202],\n        [ 0.2455, -0.2916,  0.5430]], requires_grad=True)\nb: Parameter containing:\ntensor([0.3882, 0.2735], requires_grad=True)\nloss: tensor(1.2829, grad_fn=<MseLossBackward>)\ndL/dw: tensor([[-0.0124,  0.2090,  0.1433],\n        [ 0.3311,  0.3485,  0.4343]])\ndL/db: tensor([0.4206, 0.1741])\n*** by hand\ntensor([[-0.2649, -0.4749,  0.4188],\n        [ 0.2422, -0.2951,  0.5387]], grad_fn=<SubBackward0>)\ntensor([0.3840, 0.2717], grad_fn=<SubBackward0>)\n*** by optimizer.step(\nParameter containing:\ntensor([[-0.2649, -0.4749,  0.4188],\n        [ 0.2422, -0.2951,  0.5387]], requires_grad=True)\nParameter containing:\ntensor([0.3840, 0.2717], requires_grad=True)\n"}],"source":["x = torch.tensor(1.0, requires_grad=True)\n","y = torch.tensor(2.0, requires_grad=True)\n","z = (x + 2*y)**2\n","z.backward()\n","print(x.grad) # dz/dx\n","print(y.grad) # dz/dy\n","\n","# lossを微分する\n","# バッチサンプル数=5, 入力の特徴量の次元数=3\n","x = torch.randn(5, 3)\n","# バッチサンプル数=5, 出力の特徴量の次元数=2\n","y = torch.randn(5, 2)\n","\n","# Liner層を作成\n","linear = nn.Linear(3, 2)\n","# Linear層のパラメータ\n","print('w:', linear.weight)\n","print('b:', linear.bias)\n","\n","# lossとoptimier\n","criterion = nn.MSELoss()\n","optimzier = torch.optim.SGD(linear.parameters(), lr=0.01)\n","\n","# forward\n","pred = linear(x)\n","\n","# loss = L\n","loss = criterion(pred, y)\n","print('loss:', loss)\n","\n","# backpropagation\n","loss.backward()\n","\n","# 勾配を表示\n","print('dL/dw:', linear.weight.grad)\n","print('dL/db:', linear.bias.grad)\n","\n","# 勾配を用いてパラメータを更新\n","print('*** by hand')\n","print(linear.weight.sub(0.01 * linear.weight.grad))\n","print(linear.bias.sub(0.01 * linear.bias.grad))\n","\n","# 勾配降下法\n","optimzier.step()\n","\n","# 1ステップ更新後のパラメータを表示\n","# 上の式と結果が一致することがわかる\n","print('*** by optimizer.step(')\n","print(linear.weight)\n","print(linear.bias)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}